{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm6y5ZHVgFK3"
      },
      "source": [
        "# Part 2: Prepare text documents for stamp value information queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fzTsqFk7VLZ"
      },
      "source": [
        "## Step1: Upload the demonstration dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwih2rRD7pf3"
      },
      "source": [
        "Upload the \"2012.pdf\" file, created in Part 1, to your Colab workspace in the directory '/content'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zkMwQHkb4Q_"
      },
      "source": [
        "## Step2: Define utility functions  \n",
        "**Note:** These functions are identical to those used in Part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j5HrpNiNcECv"
      },
      "outputs": [],
      "source": [
        "#print_progress(): print a progress bar\n",
        "#e.g. [██████████████████████████████--------------------] 60.67%\n",
        "def print_progress(cur_data, total_data):\n",
        "    total_bar = 50   #set total bar size to be 50\n",
        "    cur_percent = (cur_data / total_data) * 100\n",
        "    cur_bar = int((cur_data / total_data) * total_bar)\n",
        "    cur_bar_display = '█' * cur_bar + '-' * (total_bar - cur_bar)\n",
        "    print(f'\\r[{cur_bar_display}] {cur_percent:.2f}%', end='\\n' if cur_percent == 100 else '') #1)\\r: return to linehead 2)end='': not print a new line\n",
        "\n",
        "#calculate the cost of API calls based on the number of tokens used\n",
        "def calculate_token_cost(model, input_token_count=0, output_token_count=0):\n",
        "    #default price per 1 million tokens\n",
        "    input_token_price = 10.0\n",
        "    output_token_price = 30.0\n",
        "    #adjust prices based on model type\n",
        "    if model == 'gpt-4-turbo-2024-04-09':\n",
        "        pass  # Uses default prices\n",
        "    elif model == 'text-embedding-ada-002-v2':\n",
        "        input_token_price = 0.1\n",
        "        output_token_price = 0.0\n",
        "    cost = (input_token_count / 1_000_000 * input_token_price +\n",
        "            output_token_count / 1_000_000 * output_token_price)\n",
        "    return round(cost, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02vfmqdEavBG"
      },
      "source": [
        "## Step3: Convert the demonstration pdf into text files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwIc42L6-A8k"
      },
      "source": [
        "The demonstration pdf contains stamp value information. We will convert this pdf into multiple text files, creating one text file for each page. Special characters will be handled during this process. In the next step, the LLM model will only need to process a single text file to extract the requested stamp value information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYk8REgucJyh",
        "outputId": "7abca372-3743-4e7e-c8b0-460df3507c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iuvDF-sQbvq4"
      },
      "outputs": [],
      "source": [
        "#convert_pdf_to_txt_files(): converts a pdf file into separate text files, one for each page\n",
        "import fitz\n",
        "import os\n",
        "import re\n",
        "def convert_pdf_to_txt_files(pdf_path):\n",
        "    # store text files in the '/txt' folder\n",
        "    txt_dir_path = 'txt'\n",
        "    if not os.path.exists(txt_dir_path):\n",
        "        os.makedirs(txt_dir_path)\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_idx, page in enumerate(doc):  # iterate through each page of the pdf\n",
        "        page_text = page.get_text()\n",
        "        page_text = re.sub(r'[\\x00-\\x1F\\x7F\\n\\r]', ' ', page_text)   #replace control characters and line breaks with space\n",
        "        txt_file_path = os.path.join(txt_dir_path, f\"p{page_idx}.txt\")\n",
        "        with open(txt_file_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
        "            txt_file.write(page_text)\n",
        "        print_progress(page_idx + 1, len(doc))\n",
        "    doc.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1l7XlfIefnq",
        "outputId": "87bb4156-3186-4fe4-f11f-72d80588eea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[████████████████----------------------------------] 33.33%\r[█████████████████████████████████-----------------] 66.67%\r[██████████████████████████████████████████████████] 100.00%\n"
          ]
        }
      ],
      "source": [
        "#convert the demo dataset -- 2012.pdf into text files and save them in the '/txt' folder\n",
        "convert_pdf_to_txt_files('./2012.pdf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dsnV-vnIPW"
      },
      "source": [
        "## Step4: Extract stamp value info from text files using OpenAI's LLM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1tK2aO8-1Vg"
      },
      "source": [
        "1. The text files created above are unstructured, yet they contain stamp value information typically formatted as follows:   \n",
        "`scott_number, face_value, stamp_name,  mint_value, used_value `  \n",
        "For instance:  \n",
        "`4603  65¢ Baltimore Checkerspot Butterfly..............................  $7.50  $2.95`\n",
        "2. we will make OpenAI API calls to leverage GPT LLM model to extract stamp value info from the text files. We'll perform prompt engineering with 'system template' and 'user template' to guide the GPT LLM model in extracting this information accurately.\n",
        "\n",
        "Note: As of April 2024, the latest LLM model from OpenAI is \"gpt-4-turbo-2024-04-09.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXnN4vWykiMz",
        "outputId": "c817ba1b-9839-4a7b-e7b2-fa04039be5be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_o7EjB8lRId",
        "outputId": "38c39bb4-4f3f-4b55-99d8-8d05634651f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "txt/p0.txt Scott #   Mint  Used 4603  65¢ Baltimore Checkerspot Butterfly..................\n",
            "txt/p1.txt Scott #   Mint  Used 4653  45¢ William H. Johnson. .....  $3.25  $.35  4654-63 .\n",
            "txt/p2.txt Scott #   Mint  Used 4698-4701.  45¢ Innovative Choreographers  4 Stamps. ......\n"
          ]
        }
      ],
      "source": [
        "#use langchain to load text files\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = DirectoryLoader('./txt/', glob=\"*.txt\", loader_cls=TextLoader)\n",
        "docs = loader.load()\n",
        "docs_sorted = sorted(docs, key=lambda item:item.metadata['source'])    #sort documents for easier subsequent testing\n",
        "for doc in docs_sorted:\n",
        "    print(doc.metadata['source'], doc.page_content[:80])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xBEzBsqm2v9Z"
      },
      "outputs": [],
      "source": [
        "#read OpenAI API key from Colab's secrets\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ue-SrY4hf87X"
      },
      "outputs": [],
      "source": [
        "#extract_stamp_value_info(): extract stamp value information based on a user query, using the OpenAI API and the latest LLM model (gpt-4-turbo-2024-04-09)\n",
        "from langchain_core.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def extract_stamp_value_info(user_query, doc_content):\n",
        "\n",
        "    openai_llm = ChatOpenAI(temperature=0, model_name='gpt-4-turbo-2024-04-09')\n",
        "\n",
        "    system_template = SystemMessagePromptTemplate.from_template(\n",
        "        \"Assume the role of a helpful assistant with expertise in stamp collecting.\"\n",
        "    )\n",
        "\n",
        "    user_template = HumanMessagePromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        {user_query}\n",
        "        Please use the information in the provided document to determine the value.\n",
        "\n",
        "        Document Content: {doc_content}\n",
        "\n",
        "        The document contains information about stamp values in the format:\n",
        "        \"scott_number stamp_face_value stamp_name stamp_mint_value stamp_used_value\"\n",
        "\n",
        "        Note1: If the entry is for a stamp set, the 'scott_number' will contain a '-'.\n",
        "\n",
        "        Note2: If specific value information is missing, '-' will be used to denote this.\n",
        "\n",
        "        Structure your response as follows (no additional explaination required):\n",
        "        \"scott_number_or_stamp_set_number; stamp_name; face_value; mint_value; used_value\"\n",
        "\n",
        "        Note3: Use '-' in any fields where the information is not available.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_template, user_template])\n",
        "\n",
        "    chat_messages = chat_prompt.format_prompt(user_query=user_query, doc_content=doc_content).to_messages()\n",
        "    # print(chat_messages)\n",
        "\n",
        "    response = openai_llm(chat_messages)\n",
        "    # print(response)\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQyLvBCA8UXm"
      },
      "source": [
        "## Step5: Perform queries to test stamp value info extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "maZIKDLvSoSd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#query_single_stamp_value(): extract stamp value information for a given Scott number using a LLM model API call\n",
        "def query_single_stamp_value(scott_num, text_content):\n",
        "    user_query = f'Determine the value of a stamp whose scott number is {scott_num}.'\n",
        "    response = extract_stamp_value_info(user_query,  text_content)\n",
        "    #print API call cost\n",
        "    input_tokens = response.response_metadata['token_usage']['prompt_tokens']\n",
        "    output_tokens = response.response_metadata['token_usage']['completion_tokens']\n",
        "    cost = calculate_token_cost('gpt-4-turbo-2024-04-09', input_tokens, output_tokens)\n",
        "    print(f'[LLM] token:{input_tokens}(input),{output_tokens}(output) cost:${cost}')\n",
        "    #print query results\n",
        "    print(\"[scott_number_or_stamp_set_number, stamp_name, face_value, mint_value, used_value]\")\n",
        "    print(response.content)\n",
        "    scott_number, stamp_name, face_value, mint_value, used_value = re.split(r';', response.content)\n",
        "    return (scott_number, stamp_name, face_value, mint_value, used_value, input_tokens, output_tokens, cost)\n",
        "\n",
        "#query_all_stamp_values(): extract all stamp value information from the document using a LLM model API call\n",
        "def query_all_stamp_values(text_content):\n",
        "    user_query = \"Determine the value of all stamps in the document.\"\n",
        "    response = extract_stamp_value_info(user_query,  text_content)\n",
        "    #print API call cost\n",
        "    input_tokens = response.response_metadata['token_usage']['prompt_tokens']\n",
        "    output_tokens = response.response_metadata['token_usage']['completion_tokens']\n",
        "    cost = calculate_token_cost('gpt-4-turbo-2024-04-09', input_tokens, output_tokens)\n",
        "    print(f'[LLM] token:{input_tokens}(input),{output_tokens}(output) cost:${cost}')\n",
        "    #print query results\n",
        "    print(\"[scott_number_or_stamp_set_number, stamp_name, face_value, mint_value, used_value]\")\n",
        "    print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZqZLQT3kx6-",
        "outputId": "b4d5e483-ba2b-40c2-851c-2e4018bdce45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLM] token:1932(input),20(output) cost:$0.02\n",
            "[scott_number_or_stamp_set_number, stamp_name, face_value, mint_value, used_value]\n",
            "4626; Love Ribbons; 45¢; $3.50; $0.35\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('4626', ' Love Ribbons', ' 45¢', ' $3.50', ' $0.35', 1932, 20, 0.02)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#[Exam]stamp value query1: Query for stamp value information that exists within the document\n",
        "query_single_stamp_value('4626' ,docs_sorted[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE7Lgp0lrG5T",
        "outputId": "5324945f-49b2-4990-e25f-9e76669ebba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLM] token:1932(input),10(output) cost:$0.02\n",
            "[scott_number_or_stamp_set_number, stamp_name, face_value, mint_value, used_value]\n",
            "4000; -; -; -; -\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('4000', ' -', ' -', ' -', ' -', 1932, 10, 0.02)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#[Exam]stamp value query2: Query for stamp value information in cases where such information is NOT present in the document.\n",
        "query_single_stamp_value('4000' ,docs_sorted[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96Z7zfcbrZvo",
        "outputId": "6f08df92-b317-4982-9368-00eac23e05cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LLM] token:1927(input),1245(output) cost:$0.06\n",
            "[scott_number_or_stamp_set_number, stamp_name, face_value, mint_value, used_value]\n",
            "4603; Baltimore Checkerspot Butterfly; 65¢; $7.50; $2.95\n",
            "4604-07; Dogs at Work; 65¢; $13.95; $8.25\n",
            "4604; Seeing Eye Dog; 65¢; $3.50; $2.10\n",
            "4605; Therapy Dog; 65¢; $3.50; $2.10\n",
            "4606; Military Dog; 65¢; $3.50; $2.10\n",
            "4607; Rescue Dog; 65¢; $3.50; $2.10\n",
            "4608-12; Birds of Prey; 85¢; $27.95; -\n",
            "4608; Northern Goshawk; 85¢; $5.75; -\n",
            "4609; Peregrine Falcon; 85¢; $5.75; -\n",
            "4610; Golden Eagle; 85¢; $5.75; -\n",
            "4611; Osprey; 85¢; $5.75; -\n",
            "4612; Northern Harrier; 85¢; $5.75; -\n",
            "4613-17; Weathervanes; 45¢; $9.95; $2.25\n",
            "4613; Brown Rooster; 45¢; $2.00; $0.50\n",
            "4614; Cow; 45¢; $2.00; $0.50\n",
            "4615; Eagle; 45¢; $2.00; $0.50\n",
            "4616; Black Rooster; 45¢; $2.00; $0.50\n",
            "4617; Centaur; 45¢; $2.00; $0.50\n",
            "4618-22; Bonsai; 45¢; $24.95; $1.00\n",
            "4618; Sierra Juniper – Semi-cascade; 45¢; $5.00; $0.35\n",
            "4619; Black Pine – Formal Upright; 45¢; $5.00; $0.35\n",
            "4620; Banyan – Cascade; 45¢; $5.00; $0.35\n",
            "4621; Trident Maple – Informal Upright; 45¢; $5.00; $0.35\n",
            "4622; Azalea Plant – Multiple Trunk; 45¢; $5.00; $0.35\n",
            "4623; Lunar New Year; 45¢; $3.25; $0.50\n",
            "4624; Black Heritage; 45¢; $3.25; $0.50\n",
            "4625; Heart Health; 45¢; $3.25; $0.50\n",
            "4626; Love Ribbons; 45¢; $3.50; $0.35\n",
            "4627; Arizona Statehood; 45¢; $3.25; $0.50\n",
            "4628; Danny Thomas; 45¢; $3.25; $0.50\n",
            "4629-32; AVR Coil, Perf. 8½; 45¢; $12.50; $1.25\n",
            "4629; Equality; 45¢; $3.25; $0.35\n",
            "4630; Justice; 45¢; $3.25; $0.35\n",
            "4631; Freedom; 45¢; $3.25; $0.35\n",
            "4632; Liberty; 45¢; $3.25; $0.35\n",
            "4633-36; APU Coil, Perf. 9½; 45¢; $13.95; $1.25\n",
            "4633; Equality; 45¢; $3.50; $0.35\n",
            "4634; Justice; 45¢; $3.50; $0.35\n",
            "4635; Freedom; 45¢; $3.50; $0.35\n",
            "4636; Liberty; 45¢; $3.50; $0.35\n",
            "4637-40; SSP Coil, Perf. 11; 45¢; $12.50; $1.25\n",
            "4637; Equality; 45¢; $3.25; $0.35\n",
            "4638; Justice; 45¢; $3.25; $0.35\n",
            "4639; Freedom; 45¢; $3.25; $0.35\n",
            "4640; Liberty; 45¢; $3.25; $0.35\n",
            "4641-44; APU Booklet; 45¢; $14.95; $1.95\n",
            "4641; Freedom; 45¢; $3.75; $0.50\n",
            "4642; Liberty; 45¢; $3.75; $0.50\n",
            "4643; Equality; 45¢; $3.75; $0.50\n",
            "4644; Justice; 45¢; $3.75; $0.50\n",
            "4645-48; SSP Booklet; 45¢; $12.50; $1.25\n",
            "4645; Freedom; 45¢; $3.25; $0.35\n",
            "4646; Liberty; 45¢; $3.25; $0.35\n",
            "4647; Equality; 45¢; $3.25; $0.35\n",
            "4648; Justice; 45¢; $3.25; $0.35\n",
            "4649; Priority Mail; $5.15; $22.95; $12.50\n",
            "4650; Express Mail; $18.95; $64.95; $44.95\n",
            "4651-52; Cherry Blossoms Centennial; 45¢; $6.50; $0.60\n",
            "4651; Washington Monument; 45¢; $3.25; $0.35\n",
            "4652; Jefferson Monument; 45¢; $3.25; $0.35\n"
          ]
        }
      ],
      "source": [
        "#[Exam]stamp value query3: Query for all stamp value information found in the document.\n",
        "query_all_stamp_values(docs_sorted[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nECi0OKRk1kv"
      },
      "source": [
        "## Step6: Backup generated artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1byrcwLlB80"
      },
      "source": [
        "1. Artifacts for Part 3:\n",
        "\n",
        "   - **/txt**: The folder storing unstructured text files containing stamp value information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0aTbWo9wyQy8"
      },
      "outputs": [],
      "source": [
        "#pack generated artifacts into a zip file\n",
        "!zip -r data_part2.zip txt  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QidcvgppyiRh",
        "outputId": "40e45bb4-069d-4d7b-bbc8-6f82259fa220"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7e8f3bb7-6cb2-4c31-b731-d77eaea016e6\", \"data_part2.zip\", 5695)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#download the zip file (~8k) for future use\n",
        "from google.colab import files\n",
        "files.download('data_part2.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
